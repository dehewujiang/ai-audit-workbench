
import { useCallback, useRef } from 'react';
import { 
    Project, AuditProgram, AuditProcedure, ChatMessage, Finding, FraudCase, DrillTurn, 
    LoadingStateKey, ProjectHandlers, KnowledgeSnippet, DistilledContext 
} from '../types';
import { useAuth } from '../AuthContext';
import { useChat } from '../contexts/ChatContext';
import { useAudit } from '../contexts/AuditContext';
import { useGlobal } from '../contexts/GlobalContext';
import { useUI } from '../contexts/UIContext';
import * as aiService from '../services/aiService';
import { calculateMessagesTokens, THRESHOLDS } from '../utils/tokenUtils';

export const useProjectHandlers = (activeProject: Project | null): ProjectHandlers => {
    const { user } = useAuth();
    const chatCtx = useChat();
    const auditCtx = useAudit();
    const globalCtx = useGlobal();
    const { 
        showModal, closeModal, setNotification,
        setSelectedFinding, setCurrentAssessment, setAssessmentError,
        currentAuditeeProfile, setLoadingState: setUILoadingState,
        setSelectedItemId 
    } = useUI();

    // PROF-FIX: ä¿®æ­£äº† AbortController çš„æ‹¼å†™é”™è¯¯
    const abortControllerRef = useRef<AbortController | null>(null);

    // PROF-2024-NFC-001: æå–è¿‘åœºä¸Šä¸‹æ–‡ (Near-Field Context)
    // è·å–æœ€è¿‘ N æ¡å¯¹è¯è®°å½•ï¼ˆæ’é™¤ System æ¶ˆæ¯ï¼Œä»…ä¿ç•™ User/Modelï¼‰
    const getVolatileContext = useCallback((count: number = 4): string => {
        const history = chatCtx.messages
            // FIX: ChatMessage role is typed as 'user' | 'model', so checking for 'system' causes a type error.
            .filter(m => m.id !== 'init' && !m.id.startsWith('init-'))
            .slice(-count);
        
        if (history.length === 0) return "";

        return history.map(m => {
            // ç®€å•çš„æ–‡æœ¬æ¸…æ´—ï¼Œç§»é™¤è¿‡é•¿çš„æ€è€ƒè¿‡ç¨‹
            const content = m.text.replace(/<think>[\s\S]*?<\/think>/g, '').trim();
            const role = m.role === 'user' ? 'User' : 'Assistant';
            return `${role}: ${content.substring(0, 500)}${content.length > 500 ? '...' : ''}`;
        }).join('\n\n');
    }, [chatCtx.messages]);

    const finalizeMsgProcess = useCallback((msgId: string, loadingKey: LoadingStateKey, errorMsg?: string, retryPayload?: any) => {
        chatCtx.setLoadingState(loadingKey, false);
        chatCtx.updateMessage(msgId, msg => ({
            ...msg,
            processingState: null,
            ...(errorMsg ? { 
                text: msg.text + (msg.text ? "\n\n" : "") + `âš ï¸ **æ“ä½œä¸­æ–­**: ${errorMsg}`,
                actions: retryPayload ? [{ text: 'é‡æ–°æ‰§è¡Œ', actionId: 'retry', payload: { retryPayload } }] : msg.actions
            } : {})
        }));

        // PROF-2024-AFDP-001: å¯¹è¯ç»“æŸåè§¦å‘ç‰¹å¾æå–æ£€æŸ¥
        if (!errorMsg) {
            handleAutoDistillCheck();
        }
    }, [chatCtx]);

    /**
     * è‡ªåŠ¨ç‰¹å¾æå–æ£€æŸ¥
     */
    const handleAutoDistillCheck = useCallback(async () => {
        const currentTokens = calculateMessagesTokens(chatCtx.messages.map(m => ({ role: m.role, content: m.text })));
        
        // å¦‚æœè¾¾åˆ° L0 è­¦æˆ’çº¿ï¼Œä¸”æœ€è¿‘æ²¡æœ‰æå–è¿‡ï¼Œæ‰§è¡Œæå–
        if (currentTokens > THRESHOLDS.L0_CLEAN) {
            console.log("Context Pressure High. Triggering AFDP Distillation...");
            await handleDistillContext();
        }
    }, [chatCtx.messages]);

    const handleDistillContext = useCallback(async () => {
        if (!user) return;
        
        try {
            // å¯¹é™¤æœ€è¿‘ 3 è½®ä»¥å¤–çš„æ¶ˆæ¯è¿›è¡Œè„±æ°´
            const messagesToDistill = chatCtx.messages.slice(0, -6).map(m => ({ role: m.role, content: m.text }));
            if (messagesToDistill.length < 2) return;

            const summary = await aiService.distillContextTask({
                messages: messagesToDistill,
                llmProfile: globalCtx.activeLlmProfile,
                user
            });

            const newDistilled: DistilledContext = {
                historySummary: summary,
                fraudQualitative: auditCtx.lastFraudAnalysisResult || "",
                challengeQualitative: auditCtx.lastChallengeResult || "",
                findingQualitative: auditCtx.findings.map(f => f.aiAnalysis.summary).join('; '),
                lastCompressionTimestamp: new Date().toISOString()
            };

            auditCtx.updateAuditState({ distilledContext: newDistilled });
            console.log("AFDP Distillation Success.");
        } catch (e) {
            console.error("AFDP Distillation Failed:", e);
        }
    }, [user, chatCtx.messages, globalCtx.activeLlmProfile, auditCtx]);

    const buildContextString = useCallback(() => {
        if (!auditCtx.pinnedFileIds.length) return '';
        const pinnedFiles = globalCtx.globalState.knowledgeFiles.filter(f => auditCtx.pinnedFileIds.includes(f.id) && f.status === 'success');
        return aiService.buildContextStringFromFiles(pinnedFiles);
    }, [auditCtx.pinnedFileIds, globalCtx.globalState.knowledgeFiles]);

    const handleProgressChunk = useCallback((modelMsgId: string, message: string) => {
        chatCtx.updateMessage(modelMsgId, msg => {
            const steps = [...(msg.workflowSteps || [])];
            const activeIdx = steps.findIndex(s => s.status === 'in_progress');
            if (activeIdx !== -1) steps[activeIdx] = { ...steps[activeIdx], details: message };
            return { ...msg, workflowSteps: steps };
        });
    }, [chatCtx]);

    const getRevisionArtifacts = useCallback(() => {
        const activeProg = auditCtx.auditPrograms.find(p => p.id === auditCtx.activeProgramId);
        if (!activeProg) return null;
        const fraudCases = auditCtx.fraudAnalyses[activeProg.id] || [];
        const fraudCasesText = fraudCases.length > 0 
            ? fraudCases.map((c, i) => `[æ¡ˆä¾‹ ${i+1}] åœºæ™¯: ${c.scenario}\næ‰‹æ³•: ${c.potentialActors} åˆ©ç”¨ ${c.fraudTriangle.opportunity}`).join('\n---\n')
            : "";
        const combinedFraudContext = `
[èˆå¼Šå®šæ€§åˆ†æç»“è®º]:
${auditCtx.lastFraudAnalysisResult || "æœªæä¾›æ–‡å­—æ€»ç»“"}

[è¯†åˆ«åˆ°çš„å…·ä½“åœºæ™¯]:
${fraudCasesText || "æœªç”Ÿæˆå…·ä½“åœºæ™¯"}
        `.trim();
        const findingsText = auditCtx.findings.length > 0
            ? auditCtx.findings.map((f, i) => `[å·²ç¡®è®¤å‘ç° ${i+1}] çŠ¶å†µ: ${f.condition}\nå½±å“: ${f.effect}\nAI RCAåˆ†æç»“è®º: ${f.aiAnalysis.summary}`).join('\n---\n')
            : "";
        return {
            currentProgram: JSON.stringify({objective: activeProg.objective, procedures: activeProg.procedures.slice(0, 40)}),
            fraudCases: combinedFraudContext,
            challengeResults: auditCtx.lastChallengeResult || "",
            auditFindings: findingsText
        };
    }, [auditCtx.auditPrograms, auditCtx.activeProgramId, auditCtx.fraudAnalyses, auditCtx.lastChallengeResult, auditCtx.findings, auditCtx.lastFraudAnalysisResult]);

    const deleteMessage = useCallback((id: string) => chatCtx.deleteMessage(id), [chatCtx]);
    const editAndResubmit = useCallback((id: string, newText: string) => {
        const index = chatCtx.messages.findIndex(m => m.id === id);
        if (index === -1) return;
        const messagesToKeep = chatCtx.messages.slice(0, index);
        chatCtx.setMessages(messagesToKeep);
        handleSendMessage(newText);
    }, [chatCtx]);

    const handleAcceptDraft = useCallback(() => {
        if (!auditCtx.draftProgram) return;
        const newProgram = { ...auditCtx.draftProgram, id: `prog-${Date.now()}` };
        auditCtx.setAuditPrograms(prev => [...prev, newProgram]);
        auditCtx.setActiveProgramId(newProgram.id);
        auditCtx.updateAuditState({ draftProgram: null });
        chatCtx.addMessage({ role: 'model', text: `âœ… å®¡è®¡ç¨‹åºå·²å…¥åº“ã€‚` });
        auditCtx.setActiveTab('program');
        closeModal();
    }, [auditCtx, chatCtx, closeModal]);

    const handleAnalyzeAuditeeResponse = useCallback(async (finding: Finding, history: DrillTurn[]) => {
        const controller = new AbortController(); abortControllerRef.current = controller;
        const stream = aiService.analyzeAuditeeResponseStream({ finding, history, signal: controller.signal, entityProfile: globalCtx.globalState.entityProfile, projectName: activeProject?.name || 'é¡¹ç›®', llmProfile: globalCtx.activeLlmProfile || undefined, user, collectedGuidanceData: auditCtx.collectedGuidanceData });
        let text = ""; for await (const chunk of stream) text += chunk.text;
        return text;
    }, [user, globalCtx, activeProject, auditCtx.collectedGuidanceData]);

    const handleAnalyzeCommunication = useCallback(async (finding: Finding, history: DrillTurn[], userRebuttal: string) => {
        const controller = new AbortController(); abortControllerRef.current = controller;
        const stream = aiService.analyzeCommunicationStream({ finding, history, userRebuttal, auditeeProfile: currentAuditeeProfile, signal: controller.signal, entityProfile: globalCtx.globalState.entityProfile, projectName: activeProject?.name || 'é¡¹ç›®', llmProfile: globalCtx.activeLlmProfile || undefined, user, collectedGuidanceData: auditCtx.collectedGuidanceData });
        let text = ""; for await (const chunk of stream) text += chunk.text;
        return text;
    }, [user, currentAuditeeProfile, globalCtx, activeProject, auditCtx.collectedGuidanceData]);

    const handleAnalyzeFraud = useCallback(async (userInput: string = "") => {
        if (!user) return; closeModal();
        const activeProgram = auditCtx.auditPrograms.find(p => p.id === auditCtx.activeProgramId);
        if (!activeProgram) { setNotification({ message: 'æ— å¯ç”¨ç¨‹åºã€‚', type: 'error' }); return; }
        
        // PROF-2024-FRAUD-REDTEAM-V2: ç»„è£…ä¸Šä¸‹æ–‡
        const contextString = buildContextString();
        // PROF-2024-NFC-001: è·å–è¿‘åœºä¸Šä¸‹æ–‡
        const volatileContext = getVolatileContext();
        
        chatCtx.addMessage({ role: 'user', text: userInput || 'å¼€å§‹èˆå¼Šé£é™©åˆ†æ' });
        chatCtx.setLoadingState('isAnalyzingFraud', true);
        const modelMsgId = chatCtx.addMessage({ role: 'model', text: '', processingState: 'reasoning' });
        const controller = new AbortController(); abortControllerRef.current = controller;
        try {
            const stream = aiService.generateFraudPlanStream({ 
                program: activeProgram, 
                userInput, 
                longTextContext: contextString, // æ³¨å…¥æ–‡ä»¶ä¸Šä¸‹æ–‡
                volatileContext, // æ³¨å…¥è¿‘åœºå¯¹è¯ä¸Šä¸‹æ–‡
                signal: controller.signal, 
                entityProfile: globalCtx.globalState.entityProfile, 
                projectName: activeProject?.name || 'é¡¹ç›®', 
                llmProfile: globalCtx.activeLlmProfile || undefined, 
                user, 
                collectedGuidanceData: auditCtx.collectedGuidanceData 
            });
            let acc = "";
            for await (const chunk of stream) {
                if (chunk.type === 'reasoning') chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, reasoning: (msg.reasoning || '') + chunk.content }));
                if (chunk.type === 'result') { acc += chunk.content; chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, text: acc })); }
                if (chunk.type === 'workflow_update') chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, workflowSteps: chunk.steps }));
            }
            auditCtx.updateAuditState({ currentFraudPlan: acc });
            chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, processingState: null, actions: [{ text: 'ğŸ’¡ æ‰§è¡Œåˆ†æ', actionId: 'execute_fraud_analysis', payload: { fraudPlan: acc } }] }));
        } catch(e) { finalizeMsgProcess(modelMsgId, 'isAnalyzingFraud', (e as Error).message); }
    }, [user, auditCtx, chatCtx, globalCtx, activeProject, closeModal, setNotification, finalizeMsgProcess, buildContextString, getVolatileContext]);

    const handleAssessFeasibility = useCallback(async (procedure: AuditProcedure) => {
        showModal('feasibility'); setCurrentAssessment(null); setAssessmentError(null); setUILoadingState('isAssessingFeasibility', true);
        const controller = new AbortController(); abortControllerRef.current = controller;
        try {
            const stream = aiService.assessFeasibilityStream({ procedure, signal: controller.signal, entityProfile: globalCtx.globalState.entityProfile, projectName: activeProject?.name || 'é¡¹ç›®', llmProfile: globalCtx.activeLlmProfile || undefined, user, collectedGuidanceData: auditCtx.collectedGuidanceData });
            for await (const chunk of stream) { if (chunk?.data) setCurrentAssessment(chunk.data); }
        } catch(e) { setAssessmentError((e as Error).message); } finally { setUILoadingState('isAssessingFeasibility', false); }
    }, [user, globalCtx, activeProject, showModal, setCurrentAssessment, setAssessmentError, setUILoadingState, auditCtx.collectedGuidanceData]);

    const handleChallengeProgram = useCallback(async (focusNote: string) => {
        if (!user) return; closeModal();
        const latestProgram = auditCtx.auditPrograms.find(p => p.id === auditCtx.activeProgramId);
        if (!latestProgram) return;
        
        // PROF-REDTEAM-HACKER-MODE-002: Inject Context (Files + Note)
        const contextString = buildContextString();
        // PROF-2024-NFC-001: è·å–è¿‘åœºä¸Šä¸‹æ–‡
        const volatileContext = getVolatileContext();
        
        chatCtx.addMessage({ role: 'user', text: `å¯åŠ¨æŒ‘æˆ˜è€…æ¨¡å¼${focusNote ? `ï¼Œé‡ç‚¹å…³æ³¨ï¼š${focusNote}` : ''}` });
        chatCtx.setLoadingState('isChallenging', true);
        const modelMsgId = chatCtx.addMessage({ role: 'model', text: '', processingState: 'strategizing' });
        const controller = new AbortController(); abortControllerRef.current = controller;
        
        try {
            // Updated call with new parameters
            const stream = aiService.generateChallengePlanStream({ 
                latestProgram, 
                focusNote, 
                longTextContext: contextString, // Pass the built context
                volatileContext, // Pass near-field context
                signal: controller.signal, 
                entityProfile: globalCtx.globalState.entityProfile, 
                projectName: activeProject?.name || 'é¡¹ç›®', 
                llmProfile: globalCtx.activeLlmProfile || undefined, 
                user, 
                collectedGuidanceData: auditCtx.collectedGuidanceData 
            });
            
            let acc = "";
            for await (const chunk of stream) {
                if (chunk.type === 'reasoning') chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, reasoning: (msg.reasoning || '') + chunk.content }));
                if (chunk.type === 'result') { acc += chunk.content; chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, text: acc })); }
            }
            auditCtx.updateAuditState({ currentChallengePlan: acc });
            chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, processingState: null, actions: [{ text: 'âš”ï¸ æ‰§è¡ŒæŒ‘æˆ˜', actionId: 'execute_challenge', payload: { planContent: acc, focusNote } }] }));
        } catch(e) { finalizeMsgProcess(modelMsgId, 'isChallenging', (e as Error).message); }
    }, [user, auditCtx, chatCtx, globalCtx, activeProject, closeModal, buildContextString, finalizeMsgProcess, getVolatileContext]);

    const handleExecuteChallenge = useCallback(async (planContent: string, focusNote: string) => {
        if (!user) return;
        const latestProgram = auditCtx.auditPrograms.find(p => p.id === auditCtx.activeProgramId);
        if (!latestProgram) return;
        auditCtx.updateAuditState({ currentChallengePlan: null });
        chatCtx.setLoadingState('isChallenging', true);
        const modelMsgId = chatCtx.addMessage({ role: 'model', text: '', processingState: 'challenging' });
        const controller = new AbortController(); abortControllerRef.current = controller;
        try {
            const stream = aiService.executeChallengeQAStream({ latestProgram, plan: planContent, focusNote, longTextContext: buildContextString(), signal: controller.signal, entityProfile: globalCtx.globalState.entityProfile, projectName: activeProject?.name || 'é¡¹ç›®', llmProfile: globalCtx.activeLlmProfile || undefined, user, collectedGuidanceData: auditCtx.collectedGuidanceData });
            let acc = "";
            for await (const chunk of stream) {
                if (chunk.type === 'reasoning') chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, reasoning: (msg.reasoning || '') + chunk.content }));
                if (chunk.type === 'result') { acc += chunk.content; chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, text: acc })); }
            }
            auditCtx.updateAuditState({ lastChallengeResult: acc });
            finalizeMsgProcess(modelMsgId, 'isChallenging');
        } catch (e) { finalizeMsgProcess(modelMsgId, 'isChallenging', (e as Error).message); }
    }, [user, auditCtx, chatCtx, globalCtx, activeProject, buildContextString, finalizeMsgProcess]);

    const handleExecuteFindingAnalysis = useCallback(async (planContent: string) => {
        if (!user || !auditCtx.pendingFindingData) return;
        auditCtx.updateAuditState({ currentFindingAnalysisPlan: null });
        chatCtx.setLoadingState('isAnalyzing', true);
        const modelMsgId = chatCtx.addMessage({ role: 'model', text: 'ğŸ¤– æ­£åœ¨åˆ†æ RCA...', processingState: 'analyzingFinding' });
        const controller = new AbortController(); abortControllerRef.current = controller;
        try {
            const stream = aiService.executeFindingAnalysisQAStream({ ...auditCtx.pendingFindingData, plan: planContent, longTextContext: buildContextString(), signal: controller.signal, entityProfile: globalCtx.globalState.entityProfile, projectName: activeProject?.name || 'é¡¹ç›®', llmProfile: globalCtx.activeLlmProfile || undefined, user, collectedGuidanceData: auditCtx.collectedGuidanceData });
            let resultData = null;
            for await (const chunk of stream) {
                if (chunk.type === 'reasoning') chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, reasoning: (msg.reasoning || '') + chunk.content }));
                if (chunk.type === 'workflow_update') chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, workflowSteps: chunk.steps })); // PROF-FIX-003: Added workflow update
                if (chunk.type === 'json_result') resultData = chunk.data;
            }
            if (resultData) {
                const newFindingId = `finding-${Date.now()}`;
                auditCtx.addFinding({ id: newFindingId, ...auditCtx.pendingFindingData, aiAnalysis: resultData.aiAnalysis, actionItems: resultData.actionItems.map((item: any, i: number) => ({ id: `act-${i}`, text: item.text, completed: false })), status: 'Open', responseAnalysisHistory: [] });
                
                // PROF-FIX-003: Explicit Success State Update
                chatCtx.updateMessage(modelMsgId, msg => ({
                    ...msg,
                    text: 'âœ… æ ¹æœ¬åŸå› åˆ†æå·²å®Œæˆï¼Œå·²è®°å…¥å·¥ä½œåº•ç¨¿ã€‚',
                    processingState: null,
                    actions: [{ text: 'ğŸš© æŸ¥çœ‹è¯¦æƒ…', actionId: 'view_finding', payload: { findingId: newFindingId } }]
                }));

                auditCtx.setActiveTab('workbench');
                finalizeMsgProcess(modelMsgId, 'isAnalyzing');
            }
        } catch(e) { finalizeMsgProcess(modelMsgId, 'isAnalyzing', (e as Error).message); }
    }, [user, auditCtx, chatCtx, globalCtx, activeProject, buildContextString, finalizeMsgProcess]);

    const handleExecuteFraudAnalysis = useCallback(async (planContent: string) => {
        if (!user) return;
        const activeProgram = auditCtx.auditPrograms.find(p => p.id === auditCtx.activeProgramId);
        if (!activeProgram) return;
        auditCtx.updateAuditState({ currentFraudPlan: null });
        chatCtx.setLoadingState('isAnalyzingFraud', true);
        const modelMsgId = chatCtx.addMessage({ role: 'model', text: 'ğŸ¤– æ­£åœ¨æ·±åº¦åˆ†æèˆå¼Šåœºæ™¯...', processingState: 'analyzingFraud' });
        const controller = new AbortController(); abortControllerRef.current = controller;
        try {
            const stream = aiService.executeFraudAnalysisQAStream({ program: activeProgram, plan: planContent, longTextContext: buildContextString(), signal: controller.signal, entityProfile: globalCtx.globalState.entityProfile, projectName: activeProject?.name || 'é¡¹ç›®', llmProfile: globalCtx.activeLlmProfile || undefined, user, collectedGuidanceData: auditCtx.collectedGuidanceData });
            let cases = null;
            let reasoningAcc = ""; 
            for await (const chunk of stream) {
                if (chunk.type === 'reasoning') {
                    reasoningAcc += chunk.content;
                    chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, reasoning: reasoningAcc }));
                }
                if (chunk.type === 'json_result') cases = chunk.data;
            }
            if (cases) {
                auditCtx.setFraudAnalyses(prev => ({ ...prev, [activeProgram.id]: cases! }));
                auditCtx.updateAuditState({ lastFraudAnalysisResult: reasoningAcc });
                chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, processingState: null, text: 'âœ… **èˆå¼Šåˆ†æå·²å®Œæˆ**ã€‚' }));
                auditCtx.setActiveTab('fraud');
                finalizeMsgProcess(modelMsgId, 'isAnalyzingFraud');
            }
        } catch (e) { finalizeMsgProcess(modelMsgId, 'isAnalyzingFraud', (e as Error).message); }
    }, [user, auditCtx, chatCtx, globalCtx, activeProject, buildContextString, finalizeMsgProcess]);

    const handleExecutePlan = useCallback(async (planContent: string) => {
        auditCtx.updateAuditState({ currentAuditPlan: null });
        chatCtx.setLoadingState('isGenerating', true);
        const modelMsgId = chatCtx.addMessage({ role: 'model', text: 'ğŸ¤– æ­£åœ¨ç”Ÿæˆç¨‹åºè‰ç¨¿...', processingState: 'generating' });
        const controller = new AbortController(); abortControllerRef.current = controller;
        try {
            const stream = aiService.executeAutonomousQualityAssuranceStream({ plan: planContent, longTextContext: buildContextString(), signal: controller.signal, user, collectedGuidanceData: auditCtx.collectedGuidanceData, entityProfile: globalCtx.globalState.entityProfile, projectName: activeProject?.name || 'é¡¹ç›®', llmProfile: globalCtx.activeLlmProfile || undefined });
            let programData = null;
            for await (const chunk of stream) {
                if (chunk.type === 'reasoning') chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, reasoning: (msg.reasoning || '') + chunk.content }));
                if (chunk.type === 'workflow_update') chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, workflowSteps: chunk.steps })); // PROF-FIX-003: Added workflow update
                if (chunk.type === 'json_result') programData = chunk.data;
            }
            if (programData) {
                auditCtx.updateAuditState({ draftProgram: { ...programData, id: `draft-${Date.now()}`, createdAt: new Date().toISOString() } });
                
                // PROF-FIX-003: Explicit Success State Update
                chatCtx.updateMessage(modelMsgId, msg => ({
                    ...msg,
                    text: 'âœ… å®¡è®¡ç¨‹åºè‰ç¨¿å·²ç”Ÿæˆï¼Œè¯·å®¡æŸ¥ã€‚',
                    processingState: null,
                    actions: [{ text: 'ğŸ“Š å®¡æŸ¥è‰ç¨¿', actionId: 'review_draft', payload: { } }]
                }));

                showModal('draftReview');
                finalizeMsgProcess(modelMsgId, 'isGenerating');
            }
        } catch (e) { finalizeMsgProcess(modelMsgId, 'isGenerating', (e as Error).message); }
    }, [user, auditCtx, chatCtx, globalCtx, activeProject, buildContextString, showModal, finalizeMsgProcess]);

    const handleExecuteReport = useCallback(async (planContent: string) => {
        if (!user || !auditCtx.pendingReportConfig) return;
        const selectedFindings = auditCtx.findings.filter(f => auditCtx.pendingReportConfig?.includedFindingIds.includes(f.id));
        auditCtx.updateAuditState({ currentReportPlan: null });
        chatCtx.setLoadingState('isGeneratingReport', true);
        const modelMsgId = chatCtx.addMessage({ role: 'model', text: '', processingState: 'writingReport' });
        const controller = new AbortController(); abortControllerRef.current = controller;
        try {
            const stream = aiService.executeReportQAStream({ ...auditCtx.pendingReportConfig, findings: selectedFindings, plan: planContent, signal: controller.signal, entityProfile: globalCtx.globalState.entityProfile, projectName: activeProject?.name || 'é¡¹ç›®', llmProfile: globalCtx.activeLlmProfile || undefined, user, collectedGuidanceData: auditCtx.collectedGuidanceData });
            let acc = "";
            for await (const chunk of stream) {
                if (chunk.type === 'reasoning') chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, reasoning: (msg.reasoning || '') + chunk.content }));
                if (chunk.type === 'result') { acc += chunk.content; auditCtx.setGeneratedReportContent(acc); }
            }
            auditCtx.setActiveTab('report');
            finalizeMsgProcess(modelMsgId, 'isGeneratingReport');
        } catch (e) { finalizeMsgProcess(modelMsgId, 'isGeneratingReport', (e as Error).message); }
    }, [user, auditCtx, chatCtx, globalCtx, activeProject, finalizeMsgProcess]);

    const handleGenerateFindingQuestions = useCallback(async (data: any) => {
        const controller = new AbortController(); abortControllerRef.current = controller;
        const stream = aiService.generateFindingQuestionsStream({ ...data, signal: controller.signal, entityProfile: globalCtx.globalState.entityProfile, projectName: activeProject?.name || 'é¡¹ç›®', llmProfile: globalCtx.activeLlmProfile || undefined, user, collectedGuidanceData: auditCtx.collectedGuidanceData });
        let res = ""; for await (const chunk of stream) res += chunk.text;
        return res;
    }, [user, globalCtx, activeProject, auditCtx.collectedGuidanceData]);

    const handleGenerateProgram = useCallback(async (userInput: string = "") => {
        const isRevision = auditCtx.auditPrograms.length > 0;
        // PROF-2024-NFC-001: è·å–è¿‘åœºä¸Šä¸‹æ–‡
        const volatileContext = getVolatileContext();
        
        chatCtx.addMessage({ role: 'user', text: isRevision ? `ä¿®è®¢ï¼š${userInput}` : userInput || 'ç”Ÿæˆå®¡è®¡ç¨‹åº' });
        chatCtx.setLoadingState('isGenerating', true);
        const modelMsgId = chatCtx.addMessage({ role: 'model', text: '', processingState: 'planning' });
        const controller = new AbortController(); abortControllerRef.current = controller;
        try {
            const stream = aiService.generateAuditPlanStream({ 
                signal: controller.signal, 
                user, 
                collectedGuidanceData: auditCtx.collectedGuidanceData, 
                entityProfile: globalCtx.globalState.entityProfile, 
                projectName: activeProject?.name || 'é¡¹ç›®', 
                llmProfile: globalCtx.activeLlmProfile || undefined, 
                revisionContext: isRevision ? getRevisionArtifacts() : null,
                userInput, // ä¼ å…¥å½“å‰ç”¨æˆ·æŒ‡ä»¤
                volatileContext // ä¼ å…¥è¿‘åœºå¯¹è¯ä¸Šä¸‹æ–‡
            });
            let acc = '';
            for await (const chunk of stream) {
                if (chunk.type === 'reasoning') chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, reasoning: (msg.reasoning || '') + chunk.content }));
                if (chunk.type === 'result') { acc += chunk.content; chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, text: acc })); }
            }
            auditCtx.updateAuditState({ currentAuditPlan: acc });
            chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, processingState: null, actions: [{ text: 'âœ… æ‰¹å‡†å¹¶ç”Ÿæˆè¯¦ç»†ç¨‹åº', actionId: 'approve_plan', payload: { approvedPlan: acc } }] }));
            finalizeMsgProcess(modelMsgId, 'isGenerating');
        } catch (e) { finalizeMsgProcess(modelMsgId, 'isGenerating', (e as Error).message); }
    }, [user, auditCtx, chatCtx, globalCtx, activeProject, getRevisionArtifacts, finalizeMsgProcess, getVolatileContext]);

    const handleGenerateReport = useCallback((data: any) => {
        closeModal(); 
        const selectedFindings = auditCtx.findings.filter(f => data.includedFindingIds.includes(f.id));
        const volatileContext = getVolatileContext();

        auditCtx.updateAuditState({ pendingReportConfig: data, reportGenerationTitle: data.title });
        chatCtx.addMessage({ role: 'user', text: `ç”ŸæˆæŠ¥å‘Šï¼š${data.title}` });
        chatCtx.setLoadingState('isGeneratingReport', true);
        const modelMsgId = chatCtx.addMessage({ role: 'model', text: '', processingState: 'planning' });
        const controller = new AbortController(); abortControllerRef.current = controller;
        (async () => {
            try {
                const stream = aiService.generateReportPlanStream({ 
                    ...data, 
                    findings: selectedFindings, 
                    signal: controller.signal, 
                    entityProfile: globalCtx.globalState.entityProfile, 
                    projectName: activeProject?.name || 'é¡¹ç›®', 
                    llmProfile: globalCtx.activeLlmProfile || undefined, 
                    user, 
                    collectedGuidanceData: auditCtx.collectedGuidanceData,
                    volatileContext
                });
                let acc = "";
                for await (const chunk of stream) {
                    if (chunk.type === 'reasoning') chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, reasoning: (msg.reasoning || '') + chunk.content }));
                    if (chunk.type === 'result') { acc += chunk.content; chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, text: acc })); }
                }
                auditCtx.updateAuditState({ currentReportPlan: acc });
                chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, processingState: null, actions: [{ text: 'ğŸ“ æ’°å†™å…¨æ–‡', actionId: 'execute_report', payload: { reportPlan: acc } }] }));
                finalizeMsgProcess(modelMsgId, 'isGeneratingReport');
            } catch (e) { finalizeMsgProcess(modelMsgId, 'isGeneratingReport', (e as Error).message); }
        })();
    }, [user, auditCtx, chatCtx, globalCtx, activeProject, closeModal, finalizeMsgProcess, getVolatileContext]);

    const handleSendMessage = useCallback((text: string) => {
        chatCtx.addMessage({ role: 'user', text });
        const controller = new AbortController(); abortControllerRef.current = controller;
        chatCtx.setLoadingState('isLoading', true);
        const modelMsgId = chatCtx.addMessage({ role: 'model', text: '', processingState: 'loading' });
        (async () => {
            let fullText = '';
            try {
                const stream = aiService.continueConversationStream({ 
                    messages: chatCtx.messages.concat([{role: 'user', id: 'temp', text, timestamp: ''}]).map(m => ({ role: m.role, content: m.text })), 
                    longTextContext: buildContextString(), 
                    signal: controller.signal, 
                    collectedGuidanceData: auditCtx.collectedGuidanceData, 
                    entityProfile: globalCtx.globalState.entityProfile, 
                    user, 
                    projectName: activeProject?.name || 'é¡¹ç›®', 
                    llmProfile: globalCtx.activeLlmProfile || undefined,
                    distilledContext: auditCtx.distilledContext // æ³¨å…¥ç‰¹å¾è„±æ°´ä¸Šä¸‹æ–‡
                });
                for await (const chunk of stream) {
                    // PROF-FIX-DATA-ROUTING-001: Mutually Exclusive Routing
                    // Ensure reasoning chunks are ONLY routed to the reasoning field
                    // and content chunks are ONLY routed to the text field.
                    if (chunk.type === 'reasoning') {
                        chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, reasoning: (msg.reasoning || '') + chunk.text }));
                    } else if (chunk.text) { 
                        // Only process text if it's NOT reasoning (implicit 'content' type or undefined type treated as content)
                        fullText += chunk.text; 
                        chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, text: fullText })); 
                    }
                }
                finalizeMsgProcess(modelMsgId, 'isLoading');
            } catch (e) { finalizeMsgProcess(modelMsgId, 'isLoading', (e as Error).message); }
        })();
    }, [user, chatCtx, auditCtx, globalCtx, activeProject, buildContextString, finalizeMsgProcess]);

    const handleSimulateAuditeeResponse = useCallback(async (finding: Finding, history: DrillTurn[]) => {
        const controller = new AbortController(); abortControllerRef.current = controller;
        const stream = aiService.simulateAuditeeResponseStream({ finding, history, auditeeProfile: currentAuditeeProfile, signal: controller.signal, entityProfile: globalCtx.globalState.entityProfile, projectName: activeProject?.name || 'é¡¹ç›®', llmProfile: globalCtx.activeLlmProfile || undefined, user, collectedGuidanceData: auditCtx.collectedGuidanceData });
        let text = ""; for await (const chunk of stream) text += chunk.text;
        return text;
    }, [user, currentAuditeeProfile, globalCtx, activeProject, auditCtx.collectedGuidanceData]);

    const handleStartAnalysis = useCallback(() => showModal('finding'), [showModal]);
    const handleStopGeneration = useCallback(() => { if (abortControllerRef.current) abortControllerRef.current.abort(); }, []);
    
    const handleSubmitFindingAnalysis = useCallback((data: any) => {
        closeModal(); auditCtx.updateAuditState({ pendingFindingData: data });
        const volatileContext = getVolatileContext();
        
        chatCtx.addMessage({ role: 'user', text: `åˆ†æå‘ç°ï¼š${data.condition}` });
        chatCtx.setLoadingState('isAnalyzing', true);
        const modelMsgId = chatCtx.addMessage({ role: 'model', text: '', processingState: 'planning' });
        const controller = new AbortController(); abortControllerRef.current = controller;
        (async () => {
            try {
                const stream = aiService.generateFindingAnalysisPlanStream({ 
                    ...data, 
                    signal: controller.signal, 
                    entityProfile: globalCtx.globalState.entityProfile, 
                    projectName: activeProject?.name || 'é¡¹ç›®', 
                    llmProfile: globalCtx.activeLlmProfile || undefined, 
                    user, 
                    collectedGuidanceData: auditCtx.collectedGuidanceData,
                    volatileContext 
                });
                let acc = "";
                for await (const chunk of stream) {
                    if (chunk.type === 'reasoning') chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, reasoning: (msg.reasoning || '') + chunk.content }));
                    if (chunk.type === 'result') { acc += chunk.content; chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, text: acc })); }
                }
                auditCtx.updateAuditState({ currentFindingAnalysisPlan: acc });
                chatCtx.updateMessage(modelMsgId, msg => ({ ...msg, processingState: null, actions: [{ text: 'ğŸš© æ‰§è¡ŒRCAåˆ†æ', actionId: 'execute_finding_analysis', payload: { findingPlan: acc } }] }));
                finalizeMsgProcess(modelMsgId, 'isAnalyzing');
            } catch (e) { finalizeMsgProcess(modelMsgId, 'isAnalyzing', (e as Error).message); }
        })();
    }, [user, auditCtx, chatCtx, globalCtx, activeProject, closeModal, finalizeMsgProcess, getVolatileContext]);

    const handleToggleSnippet = useCallback(({ sourceId, content, type }: any) => {
        const exists = globalCtx.globalState.snippets.some(s => s.sourceId === sourceId);
        globalCtx.updateGlobalState(prev => ({ ...prev, snippets: exists ? prev.snippets.filter(s => s.sourceId !== sourceId) : [...prev.snippets, { id: `snip-${Date.now()}`, content, type, createdAt: new Date().toISOString(), projectName: activeProject?.name, sourceId }] }));
    }, [globalCtx, activeProject]);

    const handleActionClick = useCallback((messageId: string, actionId: string, payload: any) => {
        if (actionId === 'approve_plan') handleExecutePlan(payload.approvedPlan);
        else if (actionId === 'execute_challenge') handleExecuteChallenge(payload.planContent, payload.focusNote);
        else if (actionId === 'execute_fraud_analysis') handleExecuteFraudAnalysis(payload.fraudPlan);
        else if (actionId === 'execute_finding_analysis') handleExecuteFindingAnalysis(payload.findingPlan);
        else if (actionId === 'execute_report') handleExecuteReport(payload.reportPlan);
        else if (actionId === 'review_draft') showModal('draftReview');
        // PROF-FIX-003: Added view_finding handler
        else if (actionId === 'view_finding') {
            auditCtx.setActiveTab('workbench');
            setSelectedItemId(`finding-${payload.findingId}`);
        }
    }, [handleExecutePlan, handleExecuteChallenge, handleExecuteFraudAnalysis, handleExecuteFindingAnalysis, handleExecuteReport, showModal, setSelectedItemId, auditCtx.setActiveTab]);

    const handleGuidanceUpdate = useCallback((d: any, n: number) => { auditCtx.updateAuditState({ collectedGuidanceData: {...auditCtx.collectedGuidanceData, ...d}, guidanceStage: n }); }, [auditCtx]);
    const handleGuidanceSave = useCallback((d: any) => { auditCtx.setCollectedGuidanceData(prev => ({...prev, ...d})); }, [auditCtx]);
    const handleUpdateProgram = useCallback((program: AuditProgram, newProcedures: AuditProcedure[]) => { auditCtx.updateProgram({ ...program, procedures: newProcedures }); }, [auditCtx]);

    return {
        handleSendMessage, handleStopGeneration, deleteMessage, editAndResubmit,
        resendMessage: (id: string) => { const msg = chatCtx.messages.find(m => m.id === id); if (msg?.role === 'user') editAndResubmit(id, msg.text); },
        handleGenerateProgram, handleExecutePlan, handleUpdateProgram, 
        handleUpdateDraft: (p: AuditProgram) => auditCtx.updateAuditState({ draftProgram: p }),
        handleAcceptDraft, switchProgramVersion: (id: string) => auditCtx.setActiveProgramId(id),
        handleToggleSnippet, handleChallengeProgram, handleExecuteChallenge, handleAnalyzeFraud, handleExecuteFraudAnalysis,
        handleStartAnalysis, handleGenerateFindingQuestions, handleSubmitFindingAnalysis, handleExecuteFindingAnalysis, 
        handleUpdateFinding: auditCtx.updateFinding, handleAssessFeasibility, 
        handleStartCommDrill: (f: Finding) => { setSelectedFinding(f); showModal('auditeeProfile'); },
        handleStartResponseAnalysis: (f: Finding) => { setSelectedFinding(f); showModal('responseAnalysis'); },
        handleSimulateAuditeeResponse, handleAnalyzeCommunication, handleAnalyzeAuditeeResponse,
        handleGenerateReportOutline: async () => "", handleGenerateReport, handleExecuteReport,
        handleUpdateReportContent: auditCtx.setGeneratedReportContent,
        handleUpdateFraudCases: (pid: string, c: FraudCase[]) => auditCtx.updateAuditState({ fraudAnalyses: {...auditCtx.fraudAnalyses, [pid]: c} }),
        handleActionClick,
        handleTogglePinFile: (fileId: string) => {
            const currentIds = new Set(auditCtx.pinnedFileIds);
            if (currentIds.has(fileId)) currentIds.delete(fileId); else currentIds.add(fileId);
            auditCtx.setPinnedFileIds(Array.from(currentIds));
        },
        handleGuidanceUpdate, handleGuidanceSave,
        handleDistillContext
    };
};
